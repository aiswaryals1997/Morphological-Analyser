# -*- coding: utf-8 -*-
"""statistical.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pnfEOd-uGK4-olBW7oGTy-OtP5S-ZjgJ
"""

!wget https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.ml.vec

from gensim.models import KeyedVectors
import pandas as pd
import re

model =  KeyedVectors.load_word2vec_format("wiki.ml.vec", binary=False)
model.save('fastText.mal.model')



model_reloaded = KeyedVectors.load('fastText.mal.model')

from google.colab import files
uploaded = files.upload()

dataframe = pd.read_csv("data11.csv", delimiter = ',', header = None)  #reading csv data

words =list(dataframe[0])  #converting the data column into list

similar_words = []
for i in range(len(words)):
    
    similar = model_reloaded.most_similar(words[i], topn = 15)  #retrieving similar words from the model
    for j in range(len(similar)):
        similar_words.append(similar[j][0]) #appending similar words into the list
  

match_words = [] #initializing an empty list for saving matched words 

spanval = []  #initializing an empty list for saving span of matched words
for k in similar_words: 
    for l in words:
    
        start = re.search(l, k)   #using regular expression to find matching pattern from the list if string
        if start:
            match_words.append(start.string)  #appending match words to the above list
            spanval.append(start.span(0))  #appending start and end (soan) of the matched result

span_listX = [] 
span_listY = []

for k in range(0,  len(spanval)):
    span_listX.append(spanval[k][0])  #retrieving start index 
    span_listY.append(spanval[k][1])  #retrieving end index

suffix = []
prefix = []

for fg in range(0 , len(match_words)):
    suffixWord = match_words[fg][span_listY[fg]:] #slicing the word to seperate suffix
    suffix.append(suffixWord)        #appending suffix list 
    
    if span_listX[fg] > 0:
        prefixWord = match_words[fg][0:span_listX[fg]] #slicing the word to seperate prefix
        prefix.append(prefixWord)    #appending prefix list
        


    
pattern = '\u200c'                     #stray component pattern


prefix_buffer = []
for elements in prefix:
    result1 = re.sub(pattern, '', elements) #removing garbage components from prefix
    if result1 != None:
        prefix_buffer.append(result1)

prefix_buffer = list(filter(None, prefix_buffer)) #removing null components from prefix

suffix_buffer = []
for elements in suffix:
    result2 = re.sub(pattern, '', elements) #removing garbage components from suffix
    if result2 != None:
        suffix_buffer.append(result2)  

suffix_buffer = list(filter(None, suffix_buffer)) #removing null components from suffix

prefix_res = []
[prefix_res.append(x) for x in prefix_buffer if x not in prefix_res]  #removing duplicate components from prefix


suffix_res = []
[suffix_res.append(x) for x in suffix_buffer if x not in suffix_res] #removing duplicate components from suffix




prefix_df = pd.DataFrame(prefix_res)   #converting prefix list to pandas dataframe
prefix_df.to_csv('prefix.csv', encoding='utf-8', index=False)  #saving prefix data

suffix_df = pd.DataFrame(suffix_res)  #converting suffix list to pandas dataframe
suffix_df.to_csv('suffix.csv', encoding='utf-8',index=False)  #saving suffic data

prefixData = pd.read_csv('prefix.csv', delimiter = ',', header = None )  #reading prefix csv
suffixData = pd.read_csv('suffix.csv', delimiter = ',', header = None)      #reading suffix csv



suffixData_list = list(suffixData[0])  #converting suffix dataframe to list
prefixData_list = list(prefixData[0])   #converting prefix dataframe to list

print("Enter input word: ")  #user input
user_input = input()


prefix_check_list = []      

check_result_pre = None

for p_count, p_items in enumerate( prefixData_list, start=0):  #checking for prefixes in input
    check_result_pre = user_input.startswith(p_items)
    prefix_check_list.append(check_result_pre)
    
    if check_result_pre == True:            #condition, if true breaks fromloop 
        break

if check_result_pre == True:  #condition if prefix present in input 
    result_of_prefix = prefixData_list[p_count]     
    res_str = user_input.replace(result_of_prefix, '') #retrieving root word from input using prefix
    print("Root word:", res_str)  
    
elif check_result_pre == False:
    prefix_check_list = []
    res_str = ''
    check_result_pre = None



suffix_check_list = []

check_result_suf= None

for s_count, s_items in enumerate(suffixData_list, start = 0):
    check_result_suf = user_input.endswith(s_items)
    suffix_check_list.append(check_result_suf)
    
    if check_result_suf == True:
        break

if check_result_suf == True:
    result_of_suffix = suffixData_list[s_count]
    res_str = user_input.replace(result_of_suffix, '') #retrieving root word from input using suffix
    print("Root word:", res_str)
    
elif check_result_suf == False:
    suffix_check_list = []
    res_str = ''
    check_result_suf= None


if check_result_pre == None and check_result_suf == None: # condition if prefix and suffix method failed to extract root word
    print("No data found in vocabulary")